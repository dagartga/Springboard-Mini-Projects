{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a78f221",
   "metadata": {},
   "source": [
    "# Running ALS on MovieLens (PySpark)\n",
    "\n",
    "Matrix factorization by [ALS](https://spark.apache.org/docs/latest/api/python/_modules/pyspark/ml/recommendation.html#ALS) (Alternating Least Squares) is a well known collaborative filtering algorithm.\n",
    "\n",
    "This notebook provides an example of how to utilize and evaluate ALS PySpark ML (DataFrame-based API) implementation, meant for large-scale distributed datasets.\n",
    "\n",
    "The original dataset is 100M user ratings. This notebook works with a subset of the 100K user ratings.\n",
    "\n",
    "https://towardsdatascience.com/build-recommendation-system-with-pyspark-using-alternating-least-squares-als-matrix-factorisation-ebe1ad2e7679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08890212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Recommendations').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2513d4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "|     1|     70|   3.0|964982400|\n",
      "|     1|    101|   5.0|964980868|\n",
      "|     1|    110|   4.0|964982176|\n",
      "|     1|    151|   5.0|964984041|\n",
      "|     1|    157|   5.0|964984100|\n",
      "|     1|    163|   5.0|964983650|\n",
      "|     1|    216|   5.0|964981208|\n",
      "|     1|    223|   3.0|964980985|\n",
      "|     1|    231|   5.0|964981179|\n",
      "|     1|    235|   4.0|964980908|\n",
      "|     1|    260|   5.0|964981680|\n",
      "|     1|    296|   3.0|964982967|\n",
      "|     1|    316|   3.0|964982310|\n",
      "|     1|    333|   5.0|964981179|\n",
      "|     1|    349|   4.0|964982563|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the data\n",
    "movies = spark.read.csv('movies.csv', header=True)\n",
    "ratings = spark.read.csv('ratings.csv', header=True)\n",
    "ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc4683ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|      8| Tom and Huck (1995)|  Adventure|Children|\n",
      "|      9| Sudden Death (1995)|              Action|\n",
      "|     10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|\n",
      "|     12|Dracula: Dead and...|       Comedy|Horror|\n",
      "|     13|        Balto (1995)|Adventure|Animati...|\n",
      "|     14|        Nixon (1995)|               Drama|\n",
      "|     15|Cutthroat Island ...|Action|Adventure|...|\n",
      "|     16|       Casino (1995)|         Crime|Drama|\n",
      "|     17|Sense and Sensibi...|       Drama|Romance|\n",
      "|     18|   Four Rooms (1995)|              Comedy|\n",
      "|     19|Ace Ventura: When...|              Comedy|\n",
      "|     20|  Money Train (1995)|Action|Comedy|Cri...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7f3b77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+---------+--------------------+--------------------+\n",
      "|movieId|userId|rating|timestamp|               title|              genres|\n",
      "+-------+------+------+---------+--------------------+--------------------+\n",
      "|      1|     1|   4.0|964982703|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      3|     1|   4.0|964981247|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      6|     1|   4.0|964982224|         Heat (1995)|Action|Crime|Thri...|\n",
      "|     47|     1|   5.0|964983815|Seven (a.k.a. Se7...|    Mystery|Thriller|\n",
      "|     50|     1|   5.0|964982931|Usual Suspects, T...|Crime|Mystery|Thr...|\n",
      "|     70|     1|   3.0|964982400|From Dusk Till Da...|Action|Comedy|Hor...|\n",
      "|    101|     1|   5.0|964980868|Bottle Rocket (1996)|Adventure|Comedy|...|\n",
      "|    110|     1|   4.0|964982176|   Braveheart (1995)|    Action|Drama|War|\n",
      "|    151|     1|   5.0|964984041|      Rob Roy (1995)|Action|Drama|Roma...|\n",
      "|    157|     1|   5.0|964984100|Canadian Bacon (1...|          Comedy|War|\n",
      "|    163|     1|   5.0|964983650|    Desperado (1995)|Action|Romance|We...|\n",
      "|    216|     1|   5.0|964981208|Billy Madison (1995)|              Comedy|\n",
      "|    223|     1|   3.0|964980985|       Clerks (1994)|              Comedy|\n",
      "|    231|     1|   5.0|964981179|Dumb & Dumber (Du...|    Adventure|Comedy|\n",
      "|    235|     1|   4.0|964980908|      Ed Wood (1994)|        Comedy|Drama|\n",
      "|    260|     1|   5.0|964981680|Star Wars: Episod...|Action|Adventure|...|\n",
      "|    296|     1|   3.0|964982967| Pulp Fiction (1994)|Comedy|Crime|Dram...|\n",
      "|    316|     1|   3.0|964982310|     Stargate (1994)|Action|Adventure|...|\n",
      "|    333|     1|   5.0|964981179|    Tommy Boy (1995)|              Comedy|\n",
      "|    349|     1|   4.0|964982563|Clear and Present...|Action|Crime|Dram...|\n",
      "+-------+------+------+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join the ratings and movie dataframes\n",
    "movie_ratings = ratings.join(movies, ['movieId'], 'left')\n",
    "movie_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb3b5a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to view the sparsity of the data\n",
    "def get_mat_sparsity(ratings):\n",
    "    # count the total number of ratings in the dataset\n",
    "    count_nonzero = ratings.select(\"rating\").count()\n",
    "    \n",
    "    # count the number of distinct userIds and distinct movieIds\n",
    "    total_elements = ratings.select(\"userId\").distinct().count() * ratings.select(\"movieId\").distinct().count()\n",
    "    \n",
    "    # divide the numerator by the denominator\n",
    "    sparsity = (1.0 - (count_nonzero * 1.0) / total_elements)*100\n",
    "    print(\"The ratings dataframe is \", \"%.2f\" % sparsity + \"% sparse.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b180b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratings dataframe is  98.30% sparse.\n"
     ]
    }
   ],
   "source": [
    "# view the sparsity of the movie ratings data\n",
    "get_mat_sparsity(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eb752b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test and train datasets\n",
    "(train, test) = ratings.randomSplit([0.8, 0.2], seed=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bc65ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|    101|   5.0|964980868|\n",
      "|     1|   1024|   5.0|964982876|\n",
      "|     1|   1025|   5.0|964982791|\n",
      "|     1|   1029|   5.0|964982855|\n",
      "|     1|   1032|   5.0|964982791|\n",
      "|     1|   1049|   5.0|964982400|\n",
      "|     1|   1060|   4.0|964980924|\n",
      "|     1|   1073|   5.0|964981680|\n",
      "|     1|   1080|   5.0|964981327|\n",
      "|     1|   1089|   5.0|964982951|\n",
      "|     1|   1090|   4.0|964984018|\n",
      "|     1|   1092|   5.0|964983484|\n",
      "|     1|   1097|   5.0|964981680|\n",
      "|     1|    110|   4.0|964982176|\n",
      "|     1|   1136|   5.0|964981327|\n",
      "|     1|   1196|   5.0|964981827|\n",
      "|     1|   1206|   5.0|964983737|\n",
      "|     1|   1208|   4.0|964983250|\n",
      "|     1|   1214|   4.0|964981855|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a94ce29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|   1009|   3.0|964981775|\n",
      "|     1|   1023|   5.0|964982681|\n",
      "|     1|   1030|   3.0|964982903|\n",
      "|     1|   1031|   5.0|964982653|\n",
      "|     1|   1042|   4.0|964981179|\n",
      "|     1|   1127|   4.0|964982513|\n",
      "|     1|   1197|   5.0|964981872|\n",
      "|     1|   1198|   5.0|964981827|\n",
      "|     1|   1210|   5.0|964980499|\n",
      "|     1|   1213|   5.0|964982951|\n",
      "|     1|   1220|   5.0|964981909|\n",
      "|     1|   1226|   5.0|964983618|\n",
      "|     1|   1258|   3.0|964983414|\n",
      "|     1|   1270|   5.0|964983705|\n",
      "|     1|   1517|   5.0|964981107|\n",
      "|     1|   1587|   5.0|964982346|\n",
      "|     1|   1625|   5.0|964983504|\n",
      "|     1|   1804|   5.0|964983034|\n",
      "|     1|   1920|   4.0|964981780|\n",
      "|     1|   1967|   4.0|964981710|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d0f573e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId : string\n",
      "movieId : string\n",
      "rating : string\n",
      "timestamp : string\n"
     ]
    }
   ],
   "source": [
    "for col in train.dtypes:\n",
    "    print(col[0], ':', col[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51096136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert string values to integers\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "train = train.withColumn(\"userId\", train[\"userId\"].cast(IntegerType()))\n",
    "train = train.withColumn(\"movieId\", train[\"movieId\"].cast(IntegerType()))\n",
    "train = train.withColumn(\"rating\", train[\"rating\"].cast(IntegerType()))\n",
    "\n",
    "test = test.withColumn(\"userId\", test[\"userId\"].cast(IntegerType()))\n",
    "test = test.withColumn(\"movieId\", test[\"movieId\"].cast(IntegerType()))\n",
    "test = test.withColumn(\"rating\", test[\"rating\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f510f7",
   "metadata": {},
   "source": [
    "### Implicit Data Extraction\n",
    "\n",
    "The original dataframe has ratings for movies and provides us with a lot of explicit data. To extract implicit data, it can be done by creating a one hot encoding of whether a movie was watched by the user of not. Unfortunately, we only know which movies were watched and rated, not which movies were watched but not rated. This is imperfect implicit info, but still good practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "054b860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c09940fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function for one hot encoding whether a movie was watched\n",
    "def get_binary_data(ratings):\n",
    "    ratings = ratings.withColumn('binary', functions.lit(1))\n",
    "    userIds = ratings.select(\"userId\").distinct()\n",
    "    movieIds = ratings.select('movieId').distinct()\n",
    "    \n",
    "    user_movie = userIds.crossJoin(movieIds).join(ratings, ['userId', 'movieId'], 'left')\n",
    "    user_movie = user_movie.select(['userId', 'movieId', 'binary']).fillna(0)\n",
    "    return user_movie\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84706133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a one hot encoding of movies watched\n",
    "user_movie = get_binary_data(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc7969cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|binary|\n",
      "+------+-------+------+\n",
      "|   296|    296|     1|\n",
      "|   296|   1090|     0|\n",
      "|   296| 115713|     0|\n",
      "|   296|   3210|     0|\n",
      "|   296|  88140|     0|\n",
      "|   296|    829|     0|\n",
      "|   296|   2088|     0|\n",
      "|   296|   2294|     0|\n",
      "|   296|   4821|     0|\n",
      "|   296|  48738|     0|\n",
      "|   296|   3959|     0|\n",
      "|   296|  89864|     0|\n",
      "|   296|   2136|     0|\n",
      "|   296|    691|     0|\n",
      "|   296|   3606|     0|\n",
      "|   296| 121007|     0|\n",
      "|   296|   6731|     0|\n",
      "|   296|  27317|     0|\n",
      "|   296|  26082|     0|\n",
      "|   296| 100553|     0|\n",
      "+------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_movie.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2619b5a",
   "metadata": {},
   "source": [
    "### Build the ALS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0efbd56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required functions\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Create ALS model\n",
    "als = ALS(\n",
    "        userCol='userId',\n",
    "        itemCol='movieId',\n",
    "        ratingCol='rating',\n",
    "        nonnegative=True, # look at ratings greater than 0\n",
    "        implicitPrefs=False, # use only the explicit data\n",
    "        coldStartStrategy='drop' # to avoid NaN values for users in test but not in train data\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d687cee",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5f83898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the requisite packages\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3a64eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add hyperparameters and their respective values to the param grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(als.rank, [10, 50, 100, 150]) \\\n",
    "            .addGrid(als.regParam, [0.01, 0.05, 0.1, 0.15]) \\\n",
    "            .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19997a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num models to be tested:  16\n"
     ]
    }
   ],
   "source": [
    "# define evaluator as RMSE and print length of evaluator\n",
    "evaluator = RegressionEvaluator(\n",
    "            metricName='rmse',\n",
    "            labelCol='rating',\n",
    "            predictionCol='prediction')\n",
    "print(\"Num models to be tested: \", len(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4071ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build cross validation using CrossValidator\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid,\n",
    "                    evaluator=evaluator, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c503aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the cross validator to the train dataset\n",
    "model = cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15167e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9159659314001822\n"
     ]
    }
   ],
   "source": [
    "# extract the best model from the cv model\n",
    "best_model = model.bestModel\n",
    "\n",
    "# view the predictions\n",
    "test_predictions = best_model.transform(test)\n",
    "\n",
    "RMSE = evaluator.evaluate(test_predictions)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5eb22d",
   "metadata": {},
   "source": [
    "### Check the best model parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcc3a274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**BEST MODEL**\n",
      " Rank: 100\n",
      " MaxIter: 10\n",
      " RegParam: 0.15\n"
     ]
    }
   ],
   "source": [
    "print('**BEST MODEL**')\n",
    "\n",
    "# print 'Rank'\n",
    "print(\" Rank:\", best_model._java_obj.parent().getRank())\n",
    "\n",
    "# print \"MaxIter\"\n",
    "print(\" MaxIter:\", best_model._java_obj.parent().getMaxIter())\n",
    "\n",
    "# print \"RegParam\"\n",
    "print(\" RegParam:\", best_model._java_obj.parent().getRegParam())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d914e8",
   "metadata": {},
   "source": [
    "### Generate Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c8ee075a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|   471|[[7096, 4.4201956...|\n",
      "|   463|[[141718, 4.85213...|\n",
      "|   496|[[25771, 4.535957...|\n",
      "|   148|[[33649, 4.573162...|\n",
      "|   540|[[7842, 5.066717]...|\n",
      "|   392|[[25771, 4.851111...|\n",
      "|   243|[[67618, 5.656977...|\n",
      "|    31|[[33649, 5.081668...|\n",
      "|   516|[[4429, 4.7163315...|\n",
      "|   580|[[6300, 4.6681952...|\n",
      "|   251|[[33649, 5.644783...|\n",
      "|   451|[[7096, 5.339855]...|\n",
      "|    85|[[53, 4.8489943],...|\n",
      "|   137|[[1949, 4.553638]...|\n",
      "|    65|[[141718, 4.51449...|\n",
      "|   458|[[67618, 5.526861...|\n",
      "|   481|[[45503, 4.040567...|\n",
      "|    53|[[141718, 6.61839...|\n",
      "|   255|[[67618, 3.952502...|\n",
      "|   588|[[78836, 4.173175...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get 5 Recommendations for all users\n",
    "recommendations = best_model.recommendForAllUsers(5)\n",
    "recommendations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b2d3b97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = false)\n",
      " |-- recommendations: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- movieId: integer (nullable = true)\n",
      " |    |    |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommendations.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3d8d927c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---------+\n",
      "|userId|movieId|   rating|\n",
      "+------+-------+---------+\n",
      "|   471|   7096|4.4201956|\n",
      "|   471|   8477| 4.367511|\n",
      "|   471|  25771|4.3003664|\n",
      "|   471|  33649| 4.211338|\n",
      "|   471|  78836|4.1689057|\n",
      "|   463| 141718| 4.852137|\n",
      "|   463|   7842| 4.838543|\n",
      "|   463|  33649| 4.715434|\n",
      "|   463|  78836|   4.6408|\n",
      "|   463|  72171|4.6061525|\n",
      "+------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "# convert the array of values for the recommendations expected to separate columns\n",
    "recommendations = recommendations\\\n",
    "    .withColumn(\"rec_exp\", explode(\"recommendations\"))\\\n",
    "    .select('userId', \"rec_exp.*\")\n",
    "recommendations.limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c63c59e",
   "metadata": {},
   "source": [
    "### Do the recommendations make sense\n",
    "\n",
    "Select the 100th user and view the recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9fc0b993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+--------------------+--------------------+\n",
      "|movieId|userId|   rating|               title|              genres|\n",
      "+-------+------+---------+--------------------+--------------------+\n",
      "|  67618|   100| 4.871826|Strictly Sexual (...|Comedy|Drama|Romance|\n",
      "| 141718|   100|4.8585134|    Deathgasm (2015)|       Comedy|Horror|\n",
      "|  33649|   100| 4.728863|  Saving Face (2004)|Comedy|Drama|Romance|\n",
      "|   1111|   100|4.7050643|Microcosmos (Micr...|         Documentary|\n",
      "|  72171|   100|4.7050643|Black Dynamite (2...|       Action|Comedy|\n",
      "+-------+------+---------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view the recommendations\n",
    "recommendations.join(movies, on='movieId').filter('userId=100').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de43ae80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "|movieId|userId|rating| timestamp|               title|              genres|\n",
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "|   2423|   100|   5.0|1100186118|Christmas Vacatio...|              Comedy|\n",
      "|   1101|   100|   5.0|1100184137|      Top Gun (1986)|      Action|Romance|\n",
      "|   4041|   100|   5.0|1100184235|Officer and a Gen...|       Drama|Romance|\n",
      "|   1958|   100|   5.0|1100186258|Terms of Endearme...|        Comedy|Drama|\n",
      "|   5620|   100|   5.0|1100186982|Sweet Home Alabam...|      Comedy|Romance|\n",
      "|    368|   100|   4.5|1100183774|     Maverick (1994)|Adventure|Comedy|...|\n",
      "|    539|   100|   4.5|1100184295|Sleepless in Seat...|Comedy|Drama|Romance|\n",
      "|    934|   100|   4.5|1100186407|Father of the Bri...|              Comedy|\n",
      "|     16|   100|   4.5|1100185959|       Casino (1995)|         Crime|Drama|\n",
      "|    553|   100|   4.5|1100183810|    Tombstone (1993)|Action|Drama|Western|\n",
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view the movies user 100 actually likes\n",
    "ratings.join(movies, on='movieId').filter('userId=100') \\\n",
    "            .sort('rating', ascending=False).limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7994c5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deadf98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff02b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
